/**
 * Workers æ€§èƒ½åŸºå‡†æµ‹è¯•
 * 
 * ğŸ¯ ç›®æ ‡ï¼šWorkers æ¨¡å—æ€§èƒ½å’Œç¨³å®šæ€§éªŒè¯
 * 
 * æœ¬æµ‹è¯•æ–‡ä»¶éªŒè¯ Workers æ¨¡å—çš„æ€§èƒ½åŸºå‡†ï¼š
 * âœ… ååé‡åŸºå‡†æµ‹è¯•
 * âœ… å»¶è¿ŸåŸºå‡†æµ‹è¯•
 * âœ… å†…å­˜ä½¿ç”¨åŸºå‡†
 * âœ… å¹¶å‘æ€§èƒ½æµ‹è¯•
 * âœ… é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§
 * âœ… ä¸åŒè´Ÿè½½æ¨¡å¼æ€§èƒ½
 * âœ… æ‰©å±•æ€§æµ‹è¯•
 * 
 * ç¡®ä¿ Workers æ¨¡å—åœ¨å„ç§æ€§èƒ½è¦æ±‚ä¸‹çš„è¡¨ç°
 */

import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
import { EventEmitter } from 'events';

// ===========================================
// æ€§èƒ½æµ‹è¯•ç¯å¢ƒè®¾ç½®
// ===========================================

// é«˜æ€§èƒ½ Mock Workerï¼Œä¸“ä¸ºåŸºå‡†æµ‹è¯•ä¼˜åŒ–
class BenchmarkWorker extends EventEmitter {
  public isTerminated = false;
  public postMessage = vi.fn();
  public terminate = vi.fn();
  private processingCount = 0;
  private totalProcessingTime = 0;
  private maxProcessingTime = 0;
  private minProcessingTime = Infinity;
  
  constructor(scriptPath: string, options?: any) {
    super();
    
    const workerId = options?.workerData?.workerId || '';
    let baseDelay = 1;
    
    // æ ¹æ® workerId è®¾ç½®æ€§èƒ½ç‰¹å¾
    if (workerId.includes('highperf')) {
      baseDelay = 0.5;
    } else if (workerId.includes('normal')) {
      baseDelay = 2;
    } else if (workerId.includes('slow')) {
      baseDelay = 10;
    }
    
    // å¿«é€Ÿåˆå§‹åŒ–
    setTimeout(() => {
      if (!this.isTerminated) {
        this.emit('online');
      }
    }, 1);
    
    this.postMessage = vi.fn((message) => {
      if (this.isTerminated) return;
      
      const processingDelay = baseDelay + Math.random() * baseDelay; // æ·»åŠ ä¸€äº›å˜åŒ–
      const startTime = Date.now();
      
      setTimeout(() => {
        if (this.isTerminated) return;
        
        const endTime = Date.now();
        const duration = endTime - startTime;
        
        this.processingCount++;
        this.totalProcessingTime += duration;
        this.maxProcessingTime = Math.max(this.maxProcessingTime, duration);
        this.minProcessingTime = Math.min(this.minProcessingTime, duration);
        
        const response = this.generateResponse(message);
        this.emit('message', response);
      }, processingDelay);
    });
    
    this.terminate = vi.fn(() => {
      this.isTerminated = true;
      setTimeout(() => {
        this.emit('exit', 0);
      }, 0.5);
      return Promise.resolve();
    });
  }
  
  private generateResponse(message: any): any {
    switch (message.type) {
      case 'configure':
        return { type: 'configured', id: message.id };
        
      case 'processData':
        return {
          type: 'frameProcessed',
          data: [{
            data: new Uint8Array(message.data.slice(0, Math.min(message.data.length, 100))),
            timestamp: Date.now(),
            sequence: this.processingCount,
            checksumValid: true
          }],
          id: message.id
        };
        
      case 'getStats':
        return {
          type: 'stats',
          data: {
            size: Math.floor(Math.random() * 1000),
            capacity: 1024 * 1024 * 10,
            freeSpace: Math.floor(Math.random() * 1024 * 1024),
            utilizationPercent: Math.random() * 100,
            frameQueueLength: 0
          },
          id: message.id
        };
        
      case 'reset':
        this.processingCount = 0;
        this.totalProcessingTime = 0;
        this.maxProcessingTime = 0;
        this.minProcessingTime = Infinity;
        return { type: 'reset', id: message.id };
        
      default:
        throw new Error(`Unknown message type: ${message.type}`);
    }
  }
  
  // æ€§èƒ½ç»Ÿè®¡æ–¹æ³•
  public getPerformanceStats() {
    return {
      processingCount: this.processingCount,
      totalProcessingTime: this.totalProcessingTime,
      averageProcessingTime: this.totalProcessingTime / this.processingCount || 0,
      maxProcessingTime: this.maxProcessingTime === -Infinity ? 0 : this.maxProcessingTime,
      minProcessingTime: this.minProcessingTime === Infinity ? 0 : this.minProcessingTime
    };
  }
}

// Mock Worker Threads æ¨¡å— - å®Œæ•´é…ç½®
vi.mock('worker_threads', async () => {
  const EventEmitter = require('events');
  
  return {
    default: {
      Worker: BenchmarkWorker,
      isMainThread: true,
      parentPort: null
    },
    Worker: BenchmarkWorker,
    isMainThread: true,
    parentPort: null
  };
});

// Mock path æ¨¡å— - å®Œæ•´é…ç½®
vi.mock('path', () => ({
  default: { join: vi.fn((...args: string[]) => args.join('/')) },
  join: vi.fn((...args: string[]) => args.join('/'))
}));

let MultiThreadProcessorModule: any;
let MultiThreadProcessor: any;

describe('Workers Performance Benchmarks', () => {
  
  beforeEach(async () => {
    vi.clearAllMocks();
    vi.clearAllTimers();
    
    MultiThreadProcessorModule = await import('@/workers/MultiThreadProcessor');
    MultiThreadProcessor = MultiThreadProcessorModule.MultiThreadProcessor;
    
    vi.useFakeTimers();
  });
  
  afterEach(() => {
    vi.useRealTimers();
    vi.clearAllTimers();
  });

  // ===========================================
  // 1. ååé‡åŸºå‡†æµ‹è¯•
  // ===========================================
  
  describe('Throughput Benchmarks', () => {
    
    it('should achieve target throughput for small messages', async () => {
      const config = {
        operationMode: 2,
        frameDetectionMode: 0,
        startSequence: new Uint8Array([]),
        finishSequence: new Uint8Array([0x0A]),
        checksumAlgorithm: 'none',
        maxWorkers: 4
      };
      
      const processor = new MultiThreadProcessor(config);
      vi.advanceTimersByTime(50);
      
      const messageCount = 100;
      const messageSize = 64; // 64 bytes per message
      const startTime = Date.now();
      
      const tasks = [];
      for (let i = 0; i < messageCount; i++) {
        const data = new ArrayBuffer(messageSize);
        tasks.push(processor.processData(data));
      }
      
      vi.advanceTimersByTime(500);
      
      const results = await Promise.all(tasks);
      const endTime = Date.now();
      
      const duration = endTime - startTime;
      const throughputMBps = (messageCount * messageSize) / (1024 * 1024) / (duration / 1000);
      const messagesPerSecond = messageCount / (duration / 1000);
      
      expect(results).toHaveLength(messageCount);
      expect(throughputMBps).toBeGreaterThan(0.1); // è‡³å°‘ 0.1 MB/s
      expect(messagesPerSecond).toBeGreaterThan(100); // è‡³å°‘ 100 messages/s
      
      console.log(`Small Message Throughput: ${throughputMBps.toFixed(2)} MB/s, ${messagesPerSecond.toFixed(0)} msg/s`);
      
      await processor.terminate();
    });
    
    it('should handle large message throughput efficiently', async () => {
      const config = {
        operationMode: 0,
        frameDetectionMode: 2, // NoDelimiters for maximum throughput
        startSequence: new Uint8Array([]),
        finishSequence: new Uint8Array([]),
        checksumAlgorithm: 'none',
        maxWorkers: 8
      };
      
      const processor = new MultiThreadProcessor(config);
      vi.advanceTimersByTime(100);
      
      const messageCount = 20;
      const messageSize = 1024 * 1024; // 1MB per message
      const startTime = Date.now();
      
      const tasks = [];
      for (let i = 0; i < messageCount; i++) {
        const data = new ArrayBuffer(messageSize);
        tasks.push(processor.processData(data));
      }
      
      vi.advanceTimersByTime(2000);
      
      const results = await Promise.all(tasks);
      const endTime = Date.now();
      
      const duration = endTime - startTime;
      const totalDataMB = (messageCount * messageSize) / (1024 * 1024);
      const throughputMBps = totalDataMB / (duration / 1000);
      
      expect(results).toHaveLength(messageCount);
      expect(throughputMBps).toBeGreaterThan(1); // è‡³å°‘ 1 MB/s for large messages
      
      console.log(`Large Message Throughput: ${throughputMBps.toFixed(2)} MB/s`);
      
      await processor.terminate();
    });
    
    it('should scale throughput with worker count', async () => {
      const workerCounts = [1, 2, 4, 8];
      const results = [];
      
      for (const workerCount of workerCounts) {
        const config = {
          operationMode: 2,
          frameDetectionMode: 0,
          startSequence: new Uint8Array([]),
          finishSequence: new Uint8Array([0x0A]),
          checksumAlgorithm: 'none',
          maxWorkers: workerCount
        };
        
        const processor = new MultiThreadProcessor(config);
        vi.advanceTimersByTime(50);
        
        const messageCount = 50;
        const startTime = Date.now();
        
        const tasks = [];
        for (let i = 0; i < messageCount; i++) {
          tasks.push(processor.processData(new ArrayBuffer(128)));
        }
        
        vi.advanceTimersByTime(300);
        
        await Promise.all(tasks);
        const endTime = Date.now();
        
        const duration = endTime - startTime;
        const messagesPerSecond = messageCount / (duration / 1000);
        
        results.push({
          workers: workerCount,
          throughput: messagesPerSecond
        });
        
        console.log(`${workerCount} workers: ${messagesPerSecond.toFixed(0)} msg/s`);
        
        await processor.terminate();
      }
      
      // éªŒè¯éšç€Workeræ•°é‡å¢åŠ ï¼Œååé‡åº”è¯¥æå‡
      for (let i = 1; i < results.length; i++) {
        expect(results[i].throughput).toBeGreaterThan(results[i-1].throughput * 0.8);
      }
    });
  });

  // ===========================================
  // 2. å»¶è¿ŸåŸºå‡†æµ‹è¯•
  // ===========================================
  
  describe('Latency Benchmarks', () => {
    
    it('should achieve low latency for single message processing', async () => {
      const config = {
        operationMode: 2,
        frameDetectionMode: 0,
        startSequence: new Uint8Array([]),
        finishSequence: new Uint8Array([0x0A]),
        checksumAlgorithm: 'none',
        maxWorkers: 1
      };
      
      const processor = new MultiThreadProcessor(config);
      vi.advanceTimersByTime(50);
      
      const latencies = [];
      
      // æµ‹è¯•å•ä¸ªæ¶ˆæ¯çš„å»¶è¿Ÿ
      for (let i = 0; i < 10; i++) {
        const startTime = Date.now();
        await processor.processData(new ArrayBuffer(64));
        const endTime = Date.now();
        
        latencies.push(endTime - startTime);
        vi.advanceTimersByTime(10); // çŸ­æš‚é—´éš”
      }
      
      const averageLatency = latencies.reduce((a, b) => a + b, 0) / latencies.length;
      const maxLatency = Math.max(...latencies);
      const minLatency = Math.min(...latencies);
      
      expect(averageLatency).toBeLessThan(50); // å¹³å‡å»¶è¿Ÿåº”è¯¥å°äº50ms
      expect(maxLatency).toBeLessThan(100); // æœ€å¤§å»¶è¿Ÿåº”è¯¥å°äº100ms
      
      console.log(`Latency - Avg: ${averageLatency.toFixed(2)}ms, Min: ${minLatency}ms, Max: ${maxLatency}ms`);
      
      await processor.terminate();
    });
    
    it('should maintain consistent latency under load', async () => {
      const config = {
        operationMode: 2,
        frameDetectionMode: 0,
        startSequence: new Uint8Array([]),
        finishSequence: new Uint8Array([0x0A]),
        checksumAlgorithm: 'none',
        maxWorkers: 4
      };
      
      const processor = new MultiThreadProcessor(config);
      vi.advanceTimersByTime(100);
      
      const latencies = [];
      const messageCount = 50;
      
      // å¹¶å‘å‘é€æ¶ˆæ¯å¹¶æµ‹é‡å»¶è¿Ÿ
      const tasks = [];
      for (let i = 0; i < messageCount; i++) {
        const startTime = Date.now();
        const task = processor.processData(new ArrayBuffer(128))
          .then(() => {
            const endTime = Date.now();
            latencies.push(endTime - startTime);
          });
        tasks.push(task);
      }
      
      vi.advanceTimersByTime(1000);
      
      await Promise.all(tasks);
      
      const averageLatency = latencies.reduce((a, b) => a + b, 0) / latencies.length;
      const latencyStdDev = Math.sqrt(
        latencies.reduce((sum, lat) => sum + Math.pow(lat - averageLatency, 2), 0) / latencies.length
      );
      
      expect(averageLatency).toBeLessThan(100); // è´Ÿè½½ä¸‹å¹³å‡å»¶è¿Ÿ
      expect(latencyStdDev).toBeLessThan(averageLatency * 0.5); // å»¶è¿Ÿå˜åŒ–ä¸åº”å¤ªå¤§
      
      console.log(`Load Latency - Avg: ${averageLatency.toFixed(2)}ms, StdDev: ${latencyStdDev.toFixed(2)}ms`);
      
      await processor.terminate();
    });
    
    it('should handle latency spikes gracefully', async () => {
      const config = {
        operationMode: 0,
        frameDetectionMode: 0,
        startSequence: new Uint8Array([]),
        finishSequence: new Uint8Array([0x0A]),
        checksumAlgorithm: 'none',
        maxWorkers: 2
      };
      
      const processor = new MultiThreadProcessor(config);
      vi.advanceTimersByTime(50);
      
      // åˆ›å»ºä¸€ä¸ªæ…¢Workerå’Œä¸€ä¸ªå¿«Worker
      const workers = vi.mocked(BenchmarkWorker).mock.instances as BenchmarkWorker[];
      
      // æ¨¡æ‹Ÿä¸€ä¸ªWorkerå˜æ…¢
      const slowWorkerMessage = workers[0].postMessage;
      workers[0].postMessage = vi.fn((message) => {
        // æ·»åŠ é¢å¤–å»¶è¿Ÿ
        setTimeout(() => {
          slowWorkerMessage.call(workers[0], message);
        }, 50);
      });
      
      const latencies = [];
      const tasks = [];
      
      for (let i = 0; i < 10; i++) {
        const startTime = Date.now();
        const task = processor.processData(new ArrayBuffer(64))
          .then(() => {
            latencies.push(Date.now() - startTime);
          });
        tasks.push(task);
        
        vi.advanceTimersByTime(5);
      }
      
      vi.advanceTimersByTime(500);
      
      await Promise.all(tasks);
      
      // åº”è¯¥æœ‰ä¸€äº›ä»»åŠ¡ç”±å¿«Workerå¤„ç†ï¼Œå»¶è¿Ÿè¾ƒä½
      const fastLatencies = latencies.filter(lat => lat < 20);
      const slowLatencies = latencies.filter(lat => lat >= 20);
      
      expect(fastLatencies.length).toBeGreaterThan(0);
      expect(slowLatencies.length).toBeGreaterThan(0);
      
      console.log(`Latency Distribution - Fast: ${fastLatencies.length}, Slow: ${slowLatencies.length}`);
      
      await processor.terminate();
    });
  });

  // ===========================================
  // 3. å†…å­˜ä½¿ç”¨åŸºå‡†
  // ===========================================
  
  describe('Memory Usage Benchmarks', () => {
    
    it('should maintain stable memory usage during processing', async () => {
      const config = {
        operationMode: 0,
        frameDetectionMode: 0,
        startSequence: new Uint8Array([]),
        finishSequence: new Uint8Array([0x0A]),
        checksumAlgorithm: 'none',
        maxWorkers: 4
      };
      
      const processor = new MultiThreadProcessor(config);
      vi.advanceTimersByTime(100);
      
      // è®°å½•åˆå§‹çŠ¶æ€
      const initialStats = processor.getStatistics();
      
      // å¤„ç†å¤§é‡æ•°æ®
      for (let batch = 0; batch < 10; batch++) {
        const batchTasks = [];
        
        for (let i = 0; i < 20; i++) {
          batchTasks.push(processor.processData(new ArrayBuffer(1024)));
        }
        
        vi.advanceTimersByTime(100);
        await Promise.all(batchTasks);
        
        // æ£€æŸ¥å†…å­˜ä½¿ç”¨æ²¡æœ‰å¼‚å¸¸å¢é•¿
        const currentStats = processor.getStatistics();
        expect(currentStats.activeWorkers).toBe(4);
        expect(currentStats.queuedTasks).toBe(0); // ä»»åŠ¡é˜Ÿåˆ—åº”è¯¥è¢«æ¸…ç©º
      }
      
      const finalStats = processor.getStatistics();
      
      // éªŒè¯æ²¡æœ‰å†…å­˜æ³„æ¼æŒ‡æ ‡
      expect(finalStats.tasksProcessed).toBe(200);
      expect(finalStats.averageProcessingTime).toBeGreaterThan(0);
      expect(finalStats.activeWorkers).toBe(initialStats.activeWorkers);
      
      await processor.terminate();
    });
    
    it('should handle large data buffers without memory leaks', async () => {
      const config = {
        operationMode: 0,
        frameDetectionMode: 2, // NoDelimiters
        startSequence: new Uint8Array([]),
        finishSequence: new Uint8Array([]),
        checksumAlgorithm: 'none',
        maxWorkers: 2
      };
      
      const processor = new MultiThreadProcessor(config);
      vi.advanceTimersByTime(100);
      
      // å¤„ç†éå¸¸å¤§çš„æ•°æ®å—
      const largeDataSizes = [
        1024 * 1024,      // 1MB
        2 * 1024 * 1024,  // 2MB
        5 * 1024 * 1024   // 5MB
      ];
      
      for (const size of largeDataSizes) {
        const largeData = new ArrayBuffer(size);
        const dataView = new DataView(largeData);
        
        // å¡«å……ä¸€äº›æµ‹è¯•æ•°æ®
        for (let i = 0; i < Math.min(size, 1000); i++) {
          dataView.setUint8(i, i % 256);
        }
        
        const result = await processor.processData(largeData);
        
        expect(result).toHaveProperty('type', 'frameProcessed');
        expect(result.data).toHaveLength(1);
        
        vi.advanceTimersByTime(100);
      }
      
      // éªŒè¯ç³»ç»Ÿä»ç„¶å¥åº·
      expect(processor.isHealthy()).toBe(true);
      
      const stats = processor.getStatistics();
      expect(stats.tasksProcessed).toBe(3);
      expect(stats.activeWorkers).toBe(2);
      
      await processor.terminate();
    });
    
    it('should cleanup resources properly on repeated create/destroy cycles', async () => {
      const createDestroyCount = 5;
      
      for (let cycle = 0; cycle < createDestroyCount; cycle++) {
        const config = {
          operationMode: 2,
          frameDetectionMode: 0,
          startSequence: new Uint8Array([]),
          finishSequence: new Uint8Array([0x0A]),
          checksumAlgorithm: 'none',
          maxWorkers: 3
        };
        
        const processor = new MultiThreadProcessor(config);
        vi.advanceTimersByTime(50);
        
        // å¤„ç†ä¸€äº›ä»»åŠ¡
        const tasks = [];
        for (let i = 0; i < 5; i++) {
          tasks.push(processor.processData(new ArrayBuffer(256)));
        }
        
        vi.advanceTimersByTime(100);
        await Promise.all(tasks);
        
        // éªŒè¯ç»Ÿè®¡ä¿¡æ¯
        const stats = processor.getStatistics();
        expect(stats.tasksProcessed).toBe(5);
        expect(stats.activeWorkers).toBe(3);
        
        // æ¸…ç†
        await processor.terminate();
        
        // éªŒè¯æ¸…ç†å®Œæˆ
        expect(processor.getActiveWorkerCount()).toBe(0);
        expect(processor.isHealthy()).toBe(false);
      }
      
      // éªŒè¯æ€»ä½“èµ„æºä½¿ç”¨
      const totalWorkers = vi.mocked(BenchmarkWorker).mock.instances.length;
      expect(totalWorkers).toBe(createDestroyCount * 3);
      
      // æ‰€æœ‰Workeréƒ½åº”è¯¥è¢«ç»ˆæ­¢
      vi.mocked(BenchmarkWorker).mock.instances.forEach(worker => {
        expect(worker.terminate).toHaveBeenCalled();
      });
    });
  });

  // ===========================================
  // 4. å¹¶å‘æ€§èƒ½æµ‹è¯•
  // ===========================================
  
  describe('Concurrent Performance Testing', () => {
    
    it('should maintain performance under high concurrency', async () => {
      const config = {
        operationMode: 2,
        frameDetectionMode: 0,
        startSequence: new Uint8Array([]),
        finishSequence: new Uint8Array([0x0A]),
        checksumAlgorithm: 'none',
        maxWorkers: 6
      };
      
      const processor = new MultiThreadProcessor(config);
      vi.advanceTimersByTime(150);
      
      const concurrencyLevel = 50; // 50ä¸ªå¹¶å‘ä»»åŠ¡
      const startTime = Date.now();
      
      // åˆ›å»ºå¤§é‡å¹¶å‘ä»»åŠ¡
      const tasks = [];
      for (let i = 0; i < concurrencyLevel; i++) {
        const data = new ArrayBuffer(128 + (i % 100)); // ä¸åŒå¤§å°çš„æ•°æ®
        tasks.push(processor.processData(data));
      }
      
      vi.advanceTimersByTime(1000);
      
      const results = await Promise.allSettled(tasks);
      const endTime = Date.now();
      
      const successful = results.filter(r => r.status === 'fulfilled');
      const failed = results.filter(r => r.status === 'rejected');
      
      const successRate = successful.length / concurrencyLevel;
      const duration = endTime - startTime;
      const concurrentThroughput = successful.length / (duration / 1000);
      
      expect(successRate).toBeGreaterThan(0.9); // 90% æˆåŠŸç‡
      expect(concurrentThroughput).toBeGreaterThan(20); // 20 tasks/s under concurrency
      
      console.log(`Concurrency Performance - Success Rate: ${(successRate * 100).toFixed(1)}%, Throughput: ${concurrentThroughput.toFixed(1)} tasks/s`);
      
      await processor.terminate();
    });
    
    it('should balance load across workers effectively', async () => {
      const config = {
        operationMode: 0,
        frameDetectionMode: 0,
        startSequence: new Uint8Array([]),
        finishSequence: new Uint8Array([0x0A]),
        checksumAlgorithm: 'none',
        maxWorkers: 4
      };
      
      const processor = new MultiThreadProcessor(config);
      vi.advanceTimersByTime(100);
      
      const taskCount = 40; // 10 tasks per worker theoretically
      const tasks = [];
      
      for (let i = 0; i < taskCount; i++) {
        tasks.push(processor.processData(new ArrayBuffer(64)));
      }
      
      vi.advanceTimersByTime(500);
      
      await Promise.all(tasks);
      
      // æ£€æŸ¥Workerä½¿ç”¨æƒ…å†µ
      const workers = vi.mocked(BenchmarkWorker).mock.instances as BenchmarkWorker[];
      const workerUsage = workers.map(worker => worker.getPerformanceStats());
      
      const totalProcessed = workerUsage.reduce((sum, stats) => sum + stats.processingCount, 0);
      expect(totalProcessed).toBe(taskCount);
      
      // éªŒè¯è´Ÿè½½åˆ†å¸ƒç›¸å¯¹å‡åŒ€
      const averageLoad = totalProcessed / workers.length;
      const loadVariance = workerUsage.map(stats => 
        Math.abs(stats.processingCount - averageLoad)
      );
      const maxLoadVariance = Math.max(...loadVariance);
      
      expect(maxLoadVariance).toBeLessThan(averageLoad * 0.5); // è´Ÿè½½å·®å¼‚ä¸åº”å¤ªå¤§
      
      console.log(`Load Balance - Average: ${averageLoad.toFixed(1)}, Max Variance: ${maxLoadVariance.toFixed(1)}`);
      
      await processor.terminate();
    });
    
    it('should handle mixed workload patterns efficiently', async () => {
      const config = {
        operationMode: 2,
        frameDetectionMode: 0,
        startSequence: new Uint8Array([]),
        finishSequence: new Uint8Array([0x0A]),
        checksumAlgorithm: 'none',
        maxWorkers: 4
      };
      
      const processor = new MultiThreadProcessor(config);
      vi.advanceTimersByTime(100);
      
      const workloadPatterns = [
        { count: 20, size: 64, delay: 0 },    // å¿«é€Ÿå°ä»»åŠ¡
        { count: 5, size: 2048, delay: 10 },  // ä¸­ç­‰ä»»åŠ¡
        { count: 2, size: 8192, delay: 20 }   // å¤§ä»»åŠ¡
      ];
      
      const allTasks = [];
      const patternResults = [];
      
      for (const pattern of workloadPatterns) {
        const patternTasks = [];
        const startTime = Date.now();
        
        for (let i = 0; i < pattern.count; i++) {
          patternTasks.push(processor.processData(new ArrayBuffer(pattern.size)));
          vi.advanceTimersByTime(pattern.delay);
        }
        
        allTasks.push(...patternTasks);
        
        const results = await Promise.allSettled(patternTasks);
        const endTime = Date.now();
        
        patternResults.push({
          pattern,
          successCount: results.filter(r => r.status === 'fulfilled').length,
          duration: endTime - startTime,
          throughput: results.filter(r => r.status === 'fulfilled').length / ((endTime - startTime) / 1000)
        });
      }
      
      vi.advanceTimersByTime(500);
      
      // éªŒè¯æ‰€æœ‰å·¥ä½œè´Ÿè½½æ¨¡å¼éƒ½èƒ½æœ‰æ•ˆå¤„ç†
      patternResults.forEach((result, index) => {
        expect(result.successCount).toBeGreaterThan(result.pattern.count * 0.8);
        console.log(`Pattern ${index + 1} - Success: ${result.successCount}/${result.pattern.count}, Throughput: ${result.throughput.toFixed(1)} tasks/s`);
      });
      
      await processor.terminate();
    });
  });

  // ===========================================
  // 5. é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§æµ‹è¯•
  // ===========================================
  
  describe('Long Running Stability Tests', () => {
    
    it('should maintain stable performance over extended operation', async () => {
      const config = {
        operationMode: 2,
        frameDetectionMode: 0,
        startSequence: new Uint8Array([]),
        finishSequence: new Uint8Array([0x0A]),
        checksumAlgorithm: 'none',
        maxWorkers: 3
      };
      
      const processor = new MultiThreadProcessor(config);
      vi.advanceTimersByTime(100);
      
      const phaseCount = 5;
      const tasksPerPhase = 20;
      const phaseResults = [];
      
      for (let phase = 0; phase < phaseCount; phase++) {
        const phaseStartTime = Date.now();
        const phaseTasks = [];
        
        for (let i = 0; i < tasksPerPhase; i++) {
          phaseTasks.push(processor.processData(new ArrayBuffer(128 + (i % 50))));
          vi.advanceTimersByTime(2);
        }
        
        vi.advanceTimersByTime(200);
        
        const results = await Promise.all(phaseTasks);
        const phaseEndTime = Date.now();
        
        const phaseDuration = phaseEndTime - phaseStartTime;
        const phaseThroughput = tasksPerPhase / (phaseDuration / 1000);
        
        phaseResults.push({
          phase,
          throughput: phaseThroughput,
          duration: phaseDuration
        });
        
        console.log(`Phase ${phase + 1} - Throughput: ${phaseThroughput.toFixed(1)} tasks/s, Duration: ${phaseDuration}ms`);
        
        // çŸ­æš‚ä¼‘æ¯
        vi.advanceTimersByTime(50);
      }
      
      // éªŒè¯æ€§èƒ½ç¨³å®šæ€§
      const throughputs = phaseResults.map(r => r.throughput);
      const avgThroughput = throughputs.reduce((a, b) => a + b, 0) / throughputs.length;
      const throughputVariance = Math.sqrt(
        throughputs.reduce((sum, tp) => sum + Math.pow(tp - avgThroughput, 2), 0) / throughputs.length
      );
      
      expect(throughputVariance).toBeLessThan(avgThroughput * 0.3); // æ€§èƒ½å˜åŒ–ä¸åº”å¤ªå¤§
      
      // éªŒè¯ç³»ç»Ÿå¥åº·çŠ¶æ€
      expect(processor.isHealthy()).toBe(true);
      
      const finalStats = processor.getStatistics();
      expect(finalStats.tasksProcessed).toBe(phaseCount * tasksPerPhase);
      expect(finalStats.activeWorkers).toBe(3);
      
      console.log(`Stability Test - Avg Throughput: ${avgThroughput.toFixed(1)} tasks/s, Variance: ${throughputVariance.toFixed(2)}`);
      
      await processor.terminate();
    });
    
    it('should handle worker churn without performance degradation', async () => {
      const config = {
        operationMode: 0,
        frameDetectionMode: 0,
        startSequence: new Uint8Array([]),
        finishSequence: new Uint8Array([0x0A]),
        checksumAlgorithm: 'none',
        maxWorkers: 3
      };
      
      const processor = new MultiThreadProcessor(config);
      vi.advanceTimersByTime(100);
      
      const churnCycles = 3;
      const tasksPerCycle = 15;
      const churnResults = [];
      
      for (let cycle = 0; cycle < churnCycles; cycle++) {
        const cycleStartTime = Date.now();
        
        // å¼€å§‹ä»»åŠ¡å¤„ç†
        const cycleTasks = [];
        for (let i = 0; i < tasksPerCycle; i++) {
          cycleTasks.push(processor.processData(new ArrayBuffer(64)));
          vi.advanceTimersByTime(5);
        }
        
        // åœ¨å¤„ç†è¿‡ç¨‹ä¸­è§¦å‘Worker churn
        if (cycle > 0) {
          const workers = vi.mocked(BenchmarkWorker).mock.instances as BenchmarkWorker[];
          const workerToReplace = workers[cycle % workers.length];
          
          workerToReplace.emit('error', new Error(`Planned churn cycle ${cycle}`));
          vi.advanceTimersByTime(20);
        }
        
        vi.advanceTimersByTime(300);
        
        const results = await Promise.allSettled(cycleTasks);
        const cycleEndTime = Date.now();
        
        const successCount = results.filter(r => r.status === 'fulfilled').length;
        const cycleDuration = cycleEndTime - cycleStartTime;
        const cycleThroughput = successCount / (cycleDuration / 1000);
        
        churnResults.push({
          cycle,
          successCount,
          totalTasks: tasksPerCycle,
          throughput: cycleThroughput
        });
        
        console.log(`Churn Cycle ${cycle + 1} - Success: ${successCount}/${tasksPerCycle}, Throughput: ${cycleThroughput.toFixed(1)} tasks/s`);
        
        vi.advanceTimersByTime(50);
      }
      
      // éªŒè¯å³ä½¿æœ‰Worker churnï¼Œæ€§èƒ½ä»ç„¶ç¨³å®š
      const successRates = churnResults.map(r => r.successCount / r.totalTasks);
      const avgSuccessRate = successRates.reduce((a, b) => a + b, 0) / successRates.length;
      
      expect(avgSuccessRate).toBeGreaterThan(0.8); // 80% å¹³å‡æˆåŠŸç‡
      
      // æœ€åä¸€ä¸ªå‘¨æœŸåº”è¯¥æ¢å¤åˆ°æ­£å¸¸æ€§èƒ½
      const lastCycleSuccess = churnResults[churnResults.length - 1].successCount / tasksPerCycle;
      expect(lastCycleSuccess).toBeGreaterThan(0.9);
      
      console.log(`Churn Resilience - Avg Success Rate: ${(avgSuccessRate * 100).toFixed(1)}%`);
      
      await processor.terminate();
    });
  });

});